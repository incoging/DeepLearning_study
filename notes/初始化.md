### 1. Xavier初始化

**网络版本1证明**：

假设激活函数是$$tanh$$，那么它在0点的导数为1:

对于某一层的卷积：

$$y = {w_1}{x_1} + {w_2}{x_2} +  \cdots  + {w_{{n_i}}}{x_{{n_i}}} + b$$

> 其中$$n_i$$表示输入特征个数

根据概率论的方差公式：

![1533520462123](.\初始化.assets\1533520462123.png)

有当$$x_i$$是0均值的时候：

$$E(x_i^2) = Var({x_i})$$

所以，特别地，当我们假设输入和权重都是0均值时，上面乘积方差的公式可以转化为：

![1533520831955](.\初始化.assets\1533520831955.png)

进一步假设输入x和权重w是独立同分布，则有：

![1533520866835](.\初始化.assets\1533520866835.png)



于是为了保证输入和输出的方差一致，应该有：

![1533520900347](.\初始化.assets\1533520900347.png)

按照论文中的写法，某一层的输入和输出的方差可以表示为：

![1533521176831](.\初始化.assets\1533521176831.png)

其中$$z^i$$表示第$$i$$层的激活前的值，$$x$$是第$$i$$层的输入，其中$$n_i$$表示神经元的个数（好像和上面不太搭配），个人觉得$${W^{i'}}$$应该是第$$i$$个神经元的权重向量，其长度等于输入的特征个数。

反向传播计算梯度时同样具有类似的形式：  

![1533521701481](.\初始化.assets\1533521701481.png)

**综上，为了保证前向传播和反向传播时每一层的方差一致，应满足：**

![1533521755552](.\初始化.assets\1533521755552.png)

但在实际中，某一层的输入和输出往往不相等，所有，均衡考虑，使用：

![1533521824903](.\初始化.assets\1533521824903.png)

实现方法就可以是使用方差为上面的均匀分布：

![1533521882127](.\初始化.assets\1533521882127.png)

补充，怎么得到$${2 \over {{n_i} + {n_{i + 1}}}}$$：



![821971219736408541](.\初始化.assets/821971219736408541.jpg)





### 2.He初始化

**预备知识**：

2.1 方差与期望的关系

![微信截图_20180804190258](.\初始化.assets/微信截图_20180804190258.png)

对于神经网络的第$$l$$层：

![1533529208229](.\初始化.assets\1533529208229.png)

让$$W_l$$初始化为独立同分布，假定$$X_l$$也是独立同分布，并且$$W_l$$和$$X_l$$也是独立的。则有：

![1533529175950](.\初始化.assets\1533529175950.png)



现在让$$w_l$$是0均值的，根据上面的预备知识，有：

![1533529663104](.\初始化.assets\1533529663104.png)

值得注意的是$$E(x_l^2) \ne Var({x_l})$$，除非$$x_l$$是0均值的，对于ReLU激活函数，$${x_l} = \max (0,{y_{l - 1}})$$因此它不是0均值的。因此使用ReLU将会推导出和式子（7）不同的结论。

如果我们假设$$w_{l-1}​$$关于0的一个对称分布，并且$$b_{l-1}=0​$$，那么$$y_{l-1}​$$也是0均值且关于0对称分布的。这就导致了：

![1533529829285](.\初始化.assets\1533529829285.png)

代入（7）式子，有：

![1533530235183](.\初始化.assets\1533530235183.png)

对于第$$L$$层，递归上面的式子有：

![1533530315593](.\初始化.assets\1533530315593.png)

要想每一层的方差一样，则需要：

![1533530395486](.\初始化.assets\1533530395486.png)

所以， $$w_l$$要满足：

$$Var({w_l}) = {2 \over {{n_l}}}$$

















### 方差知识补充：

1. 定位参数的变动不影响方差

![1533380732271](.\初始化.assets\1533380732271.png)

2. 数值被放大常数倍

![1533380795930](.\初始化.assets\1533380795930.png)

3. 两个随机变量之间的方差

![1533380855716](.\初始化.assets\1533380855716.png)

4. 对于N个随机变量的总和

![1533380916814](.\初始化.assets\1533380916814.png)

5. 两个独立变量的乘积

![微信截图_20180805093444](.\初始化.assets/微信截图_20180805093444.png)

​	使用期望表示为：

![1533432947952](.\初始化.assets\1533432947952.png)

6. 如果两个变量是相关的，那么乘积的期望为：

![1533433000526](.\初始化.assets\1533433000526.png)



testing